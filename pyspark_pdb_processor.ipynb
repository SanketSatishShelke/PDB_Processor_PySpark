{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7746749-dde1-4b79-a39e-738ac5147712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import os\n",
    "\n",
    "def parse_pdb_line(line):\n",
    "    \"\"\"\n",
    "    Parses a single line from a PDB file to extract relevant fields.\n",
    "    \n",
    "    Args:\n",
    "        line (str): A line from the PDB file.\n",
    "        \n",
    "    Returns:\n",
    "        Row: A PySpark Row object containing extracted fields.\n",
    "    \"\"\"\n",
    "    return Row(\n",
    "        record_type=line[0:6].strip(),\n",
    "        atom_id=int(line[6:11].strip()),\n",
    "        atom_name=line[12:16].strip(),\n",
    "        residue=line[17:20].strip(),\n",
    "        chain_id=line[21:22].strip(),\n",
    "        residue_seq=int(line[22:26].strip()),\n",
    "        x=float(line[30:38].strip()),\n",
    "        y=float(line[38:46].strip()),\n",
    "        z=float(line[46:54].strip())\n",
    "    )\n",
    "\n",
    "\n",
    "def process_pdb_file(spark, file_path, output_dir):\n",
    "    \"\"\"\n",
    "    Process a single PDB file and save its ATOM and HETATM data to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        spark (SparkSession): The active SparkSession.\n",
    "        file_path (str): Path to the PDB file.\n",
    "        output_dir (str): Directory where the output CSV file will be saved.\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(file_path).replace(\".pdb\", \".txt\")\n",
    "    output_file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    # Read the PDB file into an RDD\n",
    "    rdd = spark.sparkContext.textFile(file_path)\n",
    "\n",
    "    # Filter and parse lines starting with \"ATOM\" or \"HETATM\"\n",
    "    parsed_rdd = (\n",
    "        rdd.filter(lambda line: line.startswith(\"ATOM\") or line.startswith(\"HETATM\"))\n",
    "           .map(parse_pdb_line)\n",
    "    )\n",
    "\n",
    "    # Convert RDD to DataFrame\n",
    "    df = spark.createDataFrame(parsed_rdd)\n",
    "\n",
    "    # Write DataFrame to CSV\n",
    "    df.write.csv(output_file_path, header=True, mode=\"overwrite\")\n",
    "    print(f\"Processed: {file_path} -> {output_file_path}\")\n",
    "\n",
    "\n",
    "def process_pdb_directory(spark, input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process all PDB files in a directory using PySpark.\n",
    "    \n",
    "    Args:\n",
    "        spark (SparkSession): The active SparkSession.\n",
    "        input_dir (str): Directory containing PDB files.\n",
    "        output_dir (str): Directory to save the CSV files.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    pdb_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".pdb\")]\n",
    "\n",
    "    for pdb_file in pdb_files:\n",
    "        process_pdb_file(spark, pdb_file, output_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize SparkSession\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"PDB Processing with PySpark\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Define input and output directories\n",
    "    input_directory = \"./example_pdbs\"  # Replace with the path to your PDB files\n",
    "    output_directory = \"./output\"\n",
    "\n",
    "    # Process all PDB files in the directory\n",
    "    process_pdb_directory(spark, input_directory, output_directory)\n",
    "\n",
    "    # Stop SparkSession\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
